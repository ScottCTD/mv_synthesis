{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3eca4733",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import base64\n",
    "from pathlib import Path\n",
    "import boto3\n",
    "import json\n",
    "from typing import Literal\n",
    "\n",
    "\n",
    "def encode_b64(file_path) -> str:\n",
    "    with open(file_path, \"rb\") as file:\n",
    "        return base64.b64encode(file.read()).decode(\"utf-8\")\n",
    "\n",
    "\n",
    "class Nova2OmniEmbeddings:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.client = boto3.client(\n",
    "            service_name=\"bedrock-runtime\",\n",
    "            region_name=\"us-east-1\",\n",
    "        )\n",
    "\n",
    "    async def _invoke_model(self, request_body):\n",
    "        \"\"\"\n",
    "        Returns a dictionary with the following structure:\n",
    "        {\n",
    "            \"request_id\": str,\n",
    "            \"embeddings\": [\n",
    "                {\n",
    "                    \"embedding_type\": str,\n",
    "                    \"embedding\": list[float],\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        \"\"\"\n",
    "        response = await asyncio.to_thread(\n",
    "            self.client.invoke_model,\n",
    "            body=json.dumps(request_body, indent=2),\n",
    "            modelId=\"amazon.nova-2-multimodal-embeddings-v1:0\",\n",
    "            accept=\"application/json\",\n",
    "            contentType=\"application/json\",\n",
    "        )\n",
    "        request_id = response.get(\"ResponseMetadata\").get(\"RequestId\")\n",
    "        response_body = json.loads(response.get(\"body\").read())\n",
    "\n",
    "        results = response_body[\"embeddings\"]\n",
    "        for result in results:\n",
    "            result[\"embedding_type\"] = result.pop(\"embeddingType\")\n",
    "\n",
    "        return {\n",
    "            \"request_id\": request_id,\n",
    "            \"embeddings\": results,\n",
    "        }\n",
    "\n",
    "    async def embed_text(\n",
    "        self,\n",
    "        text: str,\n",
    "        embedding_purpose: Literal[\n",
    "            \"GENERIC_INDEX\",\n",
    "            \"TEXT_RETRIEVAL\",\n",
    "            \"IMAGE_RETRIEVAL\",\n",
    "            \"VIDEO_RETRIEVAL\",\n",
    "            \"AUDIO_RETRIEVAL\",\n",
    "            \"DOCUMENT_RETRIEVAL\",\n",
    "            \"GENERIC_RETRIEVAL\",\n",
    "            \"CLASSIFICATION\",\n",
    "            \"CLUSTERING\",\n",
    "        ] = \"GENERIC_INDEX\",\n",
    "        embedding_dimension: int = 3072,\n",
    "        truncation_mode: Literal[\"START\", \"END\", \"NONE\"] = \"NONE\",\n",
    "    ):\n",
    "        request_body = {\n",
    "            \"taskType\": \"SINGLE_EMBEDDING\",\n",
    "            \"singleEmbeddingParams\": {\n",
    "                \"embeddingPurpose\": embedding_purpose,\n",
    "                \"embeddingDimension\": embedding_dimension,\n",
    "                \"text\": {\"truncationMode\": truncation_mode, \"value\": text},\n",
    "            },\n",
    "        }\n",
    "        return await self._invoke_model(request_body)\n",
    "\n",
    "    async def embed_video(\n",
    "        self,\n",
    "        video_path: str,\n",
    "        embedding_purpose: Literal[\n",
    "            \"GENERIC_INDEX\",\n",
    "            \"TEXT_RETRIEVAL\",\n",
    "            \"IMAGE_RETRIEVAL\",\n",
    "            \"VIDEO_RETRIEVAL\",\n",
    "            \"AUDIO_RETRIEVAL\",\n",
    "            \"DOCUMENT_RETRIEVAL\",\n",
    "            \"GENERIC_RETRIEVAL\",\n",
    "            \"CLASSIFICATION\",\n",
    "            \"CLUSTERING\",\n",
    "        ] = \"GENERIC_INDEX\",\n",
    "        embedding_dimension: int = 3072,\n",
    "        embedding_mode: Literal[\n",
    "            \"AUDIO_VIDEO_COMBINED\", \"AUDIO_VIDEO_SEPARATE\"\n",
    "        ] = \"AUDIO_VIDEO_COMBINED\",\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            video_path: str\n",
    "            embedding_mode: Literal[\"AUDIO_VIDEO_COMBINED\", \"AUDIO_VIDEO_SEPARATE\"]\n",
    "                - \"AUDIO_VIDEO_COMBINED\" - Will produce a single embedding combining both audible and visual content.\n",
    "                - \"AUDIO_VIDEO_SEPARATE\" - Will produce two embeddings, one for the audible content and one for the visual content.\n",
    "        \"\"\"\n",
    "        video_path = Path(video_path)\n",
    "        video_foramt = video_path.suffix[1:]\n",
    "        video_b64 = encode_b64(video_path)\n",
    "\n",
    "        request_body = {\n",
    "            \"taskType\": \"SINGLE_EMBEDDING\",\n",
    "            \"singleEmbeddingParams\": {\n",
    "                \"embeddingPurpose\": embedding_purpose,\n",
    "                \"embeddingDimension\": embedding_dimension,\n",
    "                \"video\": {\n",
    "                    \"format\": video_foramt,\n",
    "                    \"embeddingMode\": embedding_mode,\n",
    "                    \"source\": {\"bytes\": video_b64},\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "        return await self._invoke_model(request_body)\n",
    "\n",
    "    async def embed_audio(\n",
    "        self,\n",
    "        audio_path: str,\n",
    "        embedding_purpose: Literal[\n",
    "            \"GENERIC_INDEX\",\n",
    "            \"TEXT_RETRIEVAL\",\n",
    "            \"IMAGE_RETRIEVAL\",\n",
    "            \"VIDEO_RETRIEVAL\",\n",
    "            \"AUDIO_RETRIEVAL\",\n",
    "            \"DOCUMENT_RETRIEVAL\",\n",
    "            \"GENERIC_RETRIEVAL\",\n",
    "            \"CLASSIFICATION\",\n",
    "            \"CLUSTERING\",\n",
    "        ] = \"GENERIC_INDEX\",\n",
    "        embedding_dimension: int = 3072,\n",
    "    ):\n",
    "        audio_path = Path(audio_path)\n",
    "        audio_format = audio_path.suffix[1:]\n",
    "        audio_b64 = encode_b64(audio_path)\n",
    "\n",
    "        request_body = {\n",
    "            \"taskType\": \"SINGLE_EMBEDDING\",\n",
    "            \"singleEmbeddingParams\": {\n",
    "                \"embeddingPurpose\": embedding_purpose,\n",
    "                \"embeddingDimension\": embedding_dimension,\n",
    "                \"audio\": {\"format\": audio_format, \"source\": {\"bytes\": audio_b64}},\n",
    "            },\n",
    "        }\n",
    "        return await self._invoke_model(request_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "409a1db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model = Nova2OmniEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5d3cca4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationException",
     "evalue": "An error occurred (ValidationException) when calling the InvokeModel operation: Invalid Input: The input does not adhere to the expected standards. Please refer to the model user guide and adjust the input before trying again.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationException\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m rst = \u001b[38;5;28;01mawait\u001b[39;00m embed_model.embed_audio(\n\u001b[32m      2\u001b[39m     audio_path=\u001b[33m\"\u001b[39m\u001b[33m/Users/scottcui/projects/mv_synthesis/outputs/tmp_audio/0058_185.020-185.850_16k_mono.wav\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      3\u001b[39m     embedding_purpose=\u001b[33m\"\u001b[39m\u001b[33mGENERIC_INDEX\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      4\u001b[39m )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 153\u001b[39m, in \u001b[36mNova2OmniEmbeddings.embed_audio\u001b[39m\u001b[34m(self, audio_path, embedding_purpose, embedding_dimension)\u001b[39m\n\u001b[32m    143\u001b[39m audio_b64 = encode_b64(audio_path)\n\u001b[32m    145\u001b[39m request_body = {\n\u001b[32m    146\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtaskType\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mSINGLE_EMBEDDING\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    147\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33msingleEmbeddingParams\u001b[39m\u001b[33m\"\u001b[39m: {\n\u001b[32m   (...)\u001b[39m\u001b[32m    151\u001b[39m     },\n\u001b[32m    152\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._invoke_model(request_body)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 35\u001b[39m, in \u001b[36mNova2OmniEmbeddings._invoke_model\u001b[39m\u001b[34m(self, request_body)\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_invoke_model\u001b[39m(\u001b[38;5;28mself\u001b[39m, request_body):\n\u001b[32m     23\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[33;03m    Returns a dictionary with the following structure:\u001b[39;00m\n\u001b[32m     25\u001b[39m \u001b[33;03m    {\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     33\u001b[39m \u001b[33;03m    }\u001b[39;00m\n\u001b[32m     34\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.to_thread(\n\u001b[32m     36\u001b[39m         \u001b[38;5;28mself\u001b[39m.client.invoke_model,\n\u001b[32m     37\u001b[39m         body=json.dumps(request_body, indent=\u001b[32m2\u001b[39m),\n\u001b[32m     38\u001b[39m         modelId=\u001b[33m\"\u001b[39m\u001b[33mamazon.nova-2-multimodal-embeddings-v1:0\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     39\u001b[39m         accept=\u001b[33m\"\u001b[39m\u001b[33mapplication/json\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     40\u001b[39m         contentType=\u001b[33m\"\u001b[39m\u001b[33mapplication/json\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     41\u001b[39m     )\n\u001b[32m     42\u001b[39m     request_id = response.get(\u001b[33m\"\u001b[39m\u001b[33mResponseMetadata\u001b[39m\u001b[33m\"\u001b[39m).get(\u001b[33m\"\u001b[39m\u001b[33mRequestId\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     43\u001b[39m     response_body = json.loads(response.get(\u001b[33m\"\u001b[39m\u001b[33mbody\u001b[39m\u001b[33m\"\u001b[39m).read())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.7-macos-aarch64-none/lib/python3.13/asyncio/threads.py:25\u001b[39m, in \u001b[36mto_thread\u001b[39m\u001b[34m(func, *args, **kwargs)\u001b[39m\n\u001b[32m     23\u001b[39m ctx = contextvars.copy_context()\n\u001b[32m     24\u001b[39m func_call = functools.partial(ctx.run, func, *args, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m loop.run_in_executor(\u001b[38;5;28;01mNone\u001b[39;00m, func_call)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.7-macos-aarch64-none/lib/python3.13/concurrent/futures/thread.py:59\u001b[39m, in \u001b[36m_WorkItem.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     56\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     61\u001b[39m     \u001b[38;5;28mself\u001b[39m.future.set_exception(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/mv_synthesis/.venv/lib/python3.13/site-packages/botocore/client.py:602\u001b[39m, in \u001b[36mClientCreator._create_api_method.<locals>._api_call\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    598\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    599\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m() only accepts keyword arguments.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    600\u001b[39m     )\n\u001b[32m    601\u001b[39m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m602\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/mv_synthesis/.venv/lib/python3.13/site-packages/botocore/context.py:123\u001b[39m, in \u001b[36mwith_current_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m hook:\n\u001b[32m    122\u001b[39m     hook()\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/mv_synthesis/.venv/lib/python3.13/site-packages/botocore/client.py:1078\u001b[39m, in \u001b[36mBaseClient._make_api_call\u001b[39m\u001b[34m(self, operation_name, api_params)\u001b[39m\n\u001b[32m   1074\u001b[39m     error_code = request_context.get(\n\u001b[32m   1075\u001b[39m         \u001b[33m'\u001b[39m\u001b[33merror_code_override\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   1076\u001b[39m     ) \u001b[38;5;129;01mor\u001b[39;00m error_info.get(\u001b[33m\"\u001b[39m\u001b[33mCode\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1077\u001b[39m     error_class = \u001b[38;5;28mself\u001b[39m.exceptions.from_code(error_code)\n\u001b[32m-> \u001b[39m\u001b[32m1078\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[32m   1079\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1080\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[31mValidationException\u001b[39m: An error occurred (ValidationException) when calling the InvokeModel operation: Invalid Input: The input does not adhere to the expected standards. Please refer to the model user guide and adjust the input before trying again."
     ]
    }
   ],
   "source": [
    "rst = await embed_model.embed_audio(\n",
    "    audio_path=\"/Users/scottcui/projects/mv_synthesis/outputs/tmp_audio/0058_185.020-185.850_16k_mono.wav\",\n",
    "    embedding_purpose=\"GENERIC_INDEX\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6909b02d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /Users/scottcui/projects/mv_synthesis/datasets/ds1/songs/counting_stars/clips_and_lyrics/0043_133.440-137.840.wav\n",
      "Processing /Users/scottcui/projects/mv_synthesis/datasets/ds1/songs/counting_stars/clips_and_lyrics/0079_220.540-222.480.wav\n",
      "Processing /Users/scottcui/projects/mv_synthesis/datasets/ds1/songs/counting_stars/clips_and_lyrics/0044_137.840-141.280.wav\n",
      "Processing /Users/scottcui/projects/mv_synthesis/datasets/ds1/songs/counting_stars/clips_and_lyrics/0066_192.830-193.860.wav\n",
      "Processing /Users/scottcui/projects/mv_synthesis/datasets/ds1/songs/counting_stars/clips_and_lyrics/0051_162.610-164.720.wav\n",
      "Processing /Users/scottcui/projects/mv_synthesis/datasets/ds1/songs/counting_stars/clips_and_lyrics/0027_085.750-089.760.wav\n",
      "Processing /Users/scottcui/projects/mv_synthesis/datasets/ds1/songs/counting_stars/clips_and_lyrics/0012_040.670-042.580.wav\n",
      "Processing /Users/scottcui/projects/mv_synthesis/datasets/ds1/songs/counting_stars/clips_and_lyrics/0035_116.750-119.450.wav\n",
      "Processing /Users/scottcui/projects/mv_synthesis/datasets/ds1/songs/counting_stars/clips_and_lyrics/0034_107.520-116.750.wav\n",
      "Processing /Users/scottcui/projects/mv_synthesis/datasets/ds1/songs/counting_stars/clips_and_lyrics/0074_205.860-207.060.wav\n",
      "Processing /Users/scottcui/projects/mv_synthesis/datasets/ds1/songs/counting_stars/clips_and_lyrics/0088_240.810-242.230.wav\n",
      "Processing /Users/scottcui/projects/mv_synthesis/datasets/ds1/songs/counting_stars/clips_and_lyrics/0080_222.480-226.660.wav\n",
      "Processing /Users/scottcui/projects/mv_synthesis/datasets/ds1/songs/counting_stars/clips_and_lyrics/0013_042.580-044.570.wav\n",
      "Processing /Users/scottcui/projects/mv_synthesis/datasets/ds1/songs/counting_stars/clips_and_lyrics/0091_243.970-245.000.wav\n",
      "Processing /Users/scottcui/projects/mv_synthesis/datasets/ds1/songs/counting_stars/clips_and_lyrics/0005_000.790-005.490.wav\n",
      "Processing /Users/scottcui/projects/mv_synthesis/datasets/ds1/songs/counting_stars/clips_and_lyrics/0058_185.020-185.850.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/scottcui/.local/share/uv/python/cpython-3.13.7-macos-aarch64-none/lib/python3.13/ast.py:50: RuntimeWarning: coroutine 'Nova2OmniEmbeddings.embed_audio' was never awaited\n",
      "  return compile(source, filename, mode, flags,\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "ename": "ValidationException",
     "evalue": "An error occurred (ValidationException) when calling the InvokeModel operation: Invalid Input: The input does not adhere to the expected standards. Please refer to the model user guide and adjust the input before trying again.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationException\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m audio_file \u001b[38;5;129;01min\u001b[39;00m all_audio_files:\n\u001b[32m      3\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mProcessing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maudio_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     rst = \u001b[38;5;28;01mawait\u001b[39;00m embed_model.embed_audio(\n\u001b[32m      5\u001b[39m         audio_path=audio_file,\n\u001b[32m      6\u001b[39m         embedding_purpose=\u001b[33m\"\u001b[39m\u001b[33mGENERIC_INDEX\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      7\u001b[39m     )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 153\u001b[39m, in \u001b[36mNova2OmniEmbeddings.embed_audio\u001b[39m\u001b[34m(self, audio_path, embedding_purpose, embedding_dimension)\u001b[39m\n\u001b[32m    143\u001b[39m audio_b64 = encode_b64(audio_path)\n\u001b[32m    145\u001b[39m request_body = {\n\u001b[32m    146\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtaskType\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mSINGLE_EMBEDDING\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    147\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33msingleEmbeddingParams\u001b[39m\u001b[33m\"\u001b[39m: {\n\u001b[32m   (...)\u001b[39m\u001b[32m    151\u001b[39m     },\n\u001b[32m    152\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._invoke_model(request_body)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 35\u001b[39m, in \u001b[36mNova2OmniEmbeddings._invoke_model\u001b[39m\u001b[34m(self, request_body)\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_invoke_model\u001b[39m(\u001b[38;5;28mself\u001b[39m, request_body):\n\u001b[32m     23\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[33;03m    Returns a dictionary with the following structure:\u001b[39;00m\n\u001b[32m     25\u001b[39m \u001b[33;03m    {\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     33\u001b[39m \u001b[33;03m    }\u001b[39;00m\n\u001b[32m     34\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.to_thread(\n\u001b[32m     36\u001b[39m         \u001b[38;5;28mself\u001b[39m.client.invoke_model,\n\u001b[32m     37\u001b[39m         body=json.dumps(request_body, indent=\u001b[32m2\u001b[39m),\n\u001b[32m     38\u001b[39m         modelId=\u001b[33m\"\u001b[39m\u001b[33mamazon.nova-2-multimodal-embeddings-v1:0\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     39\u001b[39m         accept=\u001b[33m\"\u001b[39m\u001b[33mapplication/json\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     40\u001b[39m         contentType=\u001b[33m\"\u001b[39m\u001b[33mapplication/json\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     41\u001b[39m     )\n\u001b[32m     42\u001b[39m     request_id = response.get(\u001b[33m\"\u001b[39m\u001b[33mResponseMetadata\u001b[39m\u001b[33m\"\u001b[39m).get(\u001b[33m\"\u001b[39m\u001b[33mRequestId\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     43\u001b[39m     response_body = json.loads(response.get(\u001b[33m\"\u001b[39m\u001b[33mbody\u001b[39m\u001b[33m\"\u001b[39m).read())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.7-macos-aarch64-none/lib/python3.13/asyncio/threads.py:25\u001b[39m, in \u001b[36mto_thread\u001b[39m\u001b[34m(func, *args, **kwargs)\u001b[39m\n\u001b[32m     23\u001b[39m ctx = contextvars.copy_context()\n\u001b[32m     24\u001b[39m func_call = functools.partial(ctx.run, func, *args, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m loop.run_in_executor(\u001b[38;5;28;01mNone\u001b[39;00m, func_call)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.7-macos-aarch64-none/lib/python3.13/concurrent/futures/thread.py:59\u001b[39m, in \u001b[36m_WorkItem.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     56\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     61\u001b[39m     \u001b[38;5;28mself\u001b[39m.future.set_exception(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/mv_synthesis/.venv/lib/python3.13/site-packages/botocore/client.py:602\u001b[39m, in \u001b[36mClientCreator._create_api_method.<locals>._api_call\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    598\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    599\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m() only accepts keyword arguments.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    600\u001b[39m     )\n\u001b[32m    601\u001b[39m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m602\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/mv_synthesis/.venv/lib/python3.13/site-packages/botocore/context.py:123\u001b[39m, in \u001b[36mwith_current_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m hook:\n\u001b[32m    122\u001b[39m     hook()\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/mv_synthesis/.venv/lib/python3.13/site-packages/botocore/client.py:1078\u001b[39m, in \u001b[36mBaseClient._make_api_call\u001b[39m\u001b[34m(self, operation_name, api_params)\u001b[39m\n\u001b[32m   1074\u001b[39m     error_code = request_context.get(\n\u001b[32m   1075\u001b[39m         \u001b[33m'\u001b[39m\u001b[33merror_code_override\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   1076\u001b[39m     ) \u001b[38;5;129;01mor\u001b[39;00m error_info.get(\u001b[33m\"\u001b[39m\u001b[33mCode\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1077\u001b[39m     error_class = \u001b[38;5;28mself\u001b[39m.exceptions.from_code(error_code)\n\u001b[32m-> \u001b[39m\u001b[32m1078\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[32m   1079\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1080\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[31mValidationException\u001b[39m: An error occurred (ValidationException) when calling the InvokeModel operation: Invalid Input: The input does not adhere to the expected standards. Please refer to the model user guide and adjust the input before trying again."
     ]
    }
   ],
   "source": [
    "all_audio_files = list(Path(\"/Users/scottcui/projects/mv_synthesis/datasets/ds1/songs/counting_stars/clips_and_lyrics\").glob(\"*.wav\"))\n",
    "for audio_file in all_audio_files:\n",
    "    print(f\"Processing {audio_file}\")\n",
    "    rst = await embed_model.embed_audio(\n",
    "        audio_path=audio_file,\n",
    "        embedding_purpose=\"GENERIC_INDEX\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9923dc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_rst = await embed_model.embed_video(\n",
    "    video_path=\"../datasets/explore/videos/video_1/S1940E01-Scene-055.mp4\",\n",
    "    embedding_purpose=\"GENERIC_INDEX\",\n",
    "    embedding_mode=\"AUDIO_VIDEO_SEPARATE\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bf24331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUDIO\n",
      "VIDEO\n"
     ]
    }
   ],
   "source": [
    "for rst in video_rst[\"embeddings\"]:\n",
    "    print(rst[\"embedding_type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641ccd1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
